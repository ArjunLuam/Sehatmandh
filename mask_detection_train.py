# -*- coding: utf-8 -*-
"""mask_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f4A35qAws13i5qKx86UPqL56rhzBPAOY
"""

# import the necessary packages
from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing.image import img_to_array
from keras.preprocessing.image import load_img
from keras.utils import to_categorical
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from keras.layers import Dense , Dropout ,Flatten , MaxPooling2D
from imutils import paths
import matplotlib.pyplot as plt
import numpy as np
import os
from keras.models import Model
import random

# importing MobileNet_v2 for higher accuracy
from keras.applications import MobileNetV2
mobile = MobileNetV2(input_shape=(224,224,3),include_top=False,weights='imagenet')

#print(mobile.summary())

# layer should not be change
for layer in mobile.layers:
  layer.trainable = False


# Make output layer of mobilenet
op_layer = mobile.output
op_layer = MaxPooling2D(pool_size=(6,6))(op_layer)
op_layer = Flatten()(op_layer)
op_layer = Dense(128,activation='relu')(op_layer)
op_layer = Dropout((0.5))(op_layer)
op_layer = Dense(2,activation= 'softmax')(op_layer)

# Define model input and output
model = Model(inputs = mobile.input , outputs = op_layer)

# compiling model
model.compile(optimizer = 'adam', 
              loss = 'binary_crossentropy', 
              metrics = ['acc'])

# save model for future use
model.save('mask_model')

# path to dataset
dataset = 'dataset'

# initialize the initial learning rate, number of epochs to train for,
# and batch size
EPOCHS = 50
BS = 32

# grab the list of images in our dataset directory, then initialize
# the list of data (i.e., images) and class images
print("[INFO] loading images...")
imagePaths = list(paths.list_images(dataset))
random.seed(42)
random.shuffle(imagePaths)
data = []
labels = []
# loop over the image paths
for imagePath in imagePaths:

	# extract the class label from the filename
	label = imagePath.split(os.path.sep)[-2]
	# load the input image (150x150) and preprocess it
	image = load_img(imagePath, target_size=(224, 224))
	image = img_to_array(image)/255.
	
 
	#image = preprocess_input(image)

	# update the data and labels lists, respectively
	data.append(image)
	labels.append(label)

# convert the data and labels to NumPy arrays
data = np.array(data, dtype="float32")
labels = np.array(labels)

# perform one-hot encoding on the labels
lb = LabelBinarizer()
labels = lb.fit_transform(labels)
label_value = to_categorical(labels)

# partition the data into training and testing splits using 75% of
# the data for training and the remaining 25% for testing
(trainX, testX, trainY, testY) = train_test_split(data, label_value,
	test_size=0.20, stratify=labels, random_state=42,shuffle = True)

aug_train = ImageDataGenerator(rescale= 1.0/255.,
	rotation_range=20,
	zoom_range=0.15,
	width_shift_range=0.2,
	height_shift_range=0.2,
	shear_range=0.15,
	horizontal_flip=True,
	fill_mode="nearest")

aug_test  = ImageDataGenerator(rescale= 1.0/255.)

hist = model.fit_generator(steps_per_epoch=len(trainX)//BS,
                           generator=aug_train.flow(trainX, trainY, batch_size=BS),
                           validation_data= (testX, testY),
                           validation_steps=len(testX)//BS,
                           epochs=EPOCHS)

# print accuracy and loss graph
import matplotlib.pyplot as plt
plt.plot(hist.history["acc"])
plt.plot(hist.history['val_acc'])
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title("model accuracy")
plt.ylabel("Accuracy")
plt.xlabel("Epoch")
plt.legend(["Accuracy","Validation Accuracy","loss","Validation Loss"])
plt.show()

# save model weights
model.save_weights('/content/drive/My Drive/Colab Notebooks/mask_model_weights.h5')

#from keras.models import load_model
#model = load_model('/content/drive/My Drive/Colab Notebooks/mask_model',custom_objects=None, compile=True)

# printing confusion matrix
from sklearn.metrics import confusion_matrix
y_pred = model.predict(testX)
y_p = np.argmax(y_pred,axis=1)
y_true = np.argmax(testY,axis=1)
print(confusion_matrix(y_true,y_p))

